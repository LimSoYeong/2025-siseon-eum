import time, json, gc
from pathlib import Path
from PIL import Image
import torch

from model_loader import get_model, get_processor

# ====== ê²½ë¡œ ì„¤ì • ======
base_dir = Path(__file__).resolve().parent.parent
out_path = base_dir / "qwen" / "results_time_compare.jsonl"
image_dir = base_dir / "data" / "img"
image_files = sorted(list(image_dir.glob("*.jpg")) + list(image_dir.glob("*.png")))

# ====== ì €ì¥ í•¨ìˆ˜ ======
def save_result_jsonl(record, path=out_path):
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")


# ====== ë¶„ë¥˜ìš© í”„ë¡¬í”„íŠ¸ ======
DOC_TYPE_PROMPT = """
ë‹¤ìŒ ë¬¸ì„œê°€ ì–´ë–¤ ìœ í˜•ì¸ì§€ í•˜ë‚˜ë§Œ ì„ íƒí•´ì„œ ì¶œë ¥í•˜ì„¸ìš”.
- ê³ ì§€ì„œ
- ì•ˆë‚´ë¬¸-ê±´ê°•
- ì•ˆë‚´ë¬¸-ìƒí™œ
- ì•ˆë‚´ë¬¸-ê¸ˆìœµ
- ê¸°íƒ€

ì¡°ê±´:
- ìœ í˜• ì´ë¦„ë§Œ ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš” (ì˜ˆ: ê³ ì§€ì„œ, ì•ˆë‚´ë¬¸-ìƒí™œ, ê¸°íƒ€)
- ë‹¤ë¥¸ ì„¤ëª…ì€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”
"""

# ====== ìš”ì•½ìš© í”„ë¡¬í”„íŠ¸ (ìœ í˜•ë³„ë¡œ ë³€ìˆ˜ ë”°ë¡œ) ======
A_PROMPT = """
ë‹¤ìŒ ë¬¸ì„œë¥¼ ë³´ê³  ì–´ë¥´ì‹ ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.

ë‹¨ê³„:
    1. ë¬¸ì„œë¥¼ ì½ê³  1ì°¨ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.
    2. ì•„ë˜ ì§ˆë¬¸ì„ ìŠ¤ìŠ¤ë¡œì—ê²Œ í•˜ë©° ê²€í† í•˜ê³ , ìˆ˜ì •ì´ í•„ìš”í•˜ë‹¤ë©´ ë³´ì™„í•˜ì—¬ ìµœì¢… ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.

ê²€í†  ì§ˆë¬¸:
    - ë¹ ëœ¨ë¦° ì¤‘ìš”í•œ í•­ëª©(ë‚©ë¶€ ì´ ê¸ˆì•¡, ë‚ ì§œ, ë‚©ë¶€ ë§ˆê°ì¼ ë“±)ì€ ì—†ë‚˜ìš”?
    - ì´ ê³ ì§€ì„œê°€ ë¬´ìŠ¨ ëˆ(ì„¸ê¸ˆÂ·ìš”ê¸ˆ) ê³ ì§€ì„œì¸ì§€ ëª…í™•í•˜ê²Œ ì•Œë ¤ì£¼ì—ˆë‚˜ìš”? (ì˜ˆ: ìë™ì°¨ì„¸, ì „ê¸°ìš”ê¸ˆ, ê±´ê°•ë³´í—˜ë£Œ ë“±)
    - ì–´ë¥´ì‹ ì´ ë“£ê¸°ì— ì´í•´í•˜ê¸° ì–´ë ¤ìš´ í‘œí˜„ì€ ì—†ë‚˜ìš”?
    - ê¸ˆì•¡ê³¼ ë§ˆê°ì¼ì€ ì¹œìˆ™í•œ ë‹¨ìœ„ì™€ ë§íˆ¬ë¡œ í‘œí˜„ë˜ì—ˆë‚˜ìš”?

ì¶œë ¥ ì¡°ê±´:
    - ìµœì¢… 2~3ë¬¸ì¥ ìš”ì•½ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    - ê²€í†  ê³¼ì •ì´ë‚˜ ì¤‘ê°„ ìš”ì•½ì€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

"""

    
HEALTH_PROMPT = """
    ë‹¤ìŒ ê±´ê°• ì•ˆë‚´ë¬¸ì„ ë¶„ì„í•˜ì—¬ ì–´ë¥´ì‹ ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.  
    ì˜ˆì‹œ, ìê°€ ì ê²€ ì§ˆë¬¸, í•µì‹¬ ìš”ì†Œë¥¼ ì°¸ê³ í•˜ë˜,  
    ì¤‘ê°„ ê³¼ì •ì€ ì¶œë ¥í•˜ì§€ ë§ê³ , 'ì‰¬ìš´ ë§ ìš”ì•½:' í•œ ì¤„ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

    ì˜ˆì‹œ:
        ì›ë¬¸:
            "â—‹ 8ì›” 10ì¼ ì˜¤ì „ 9ì‹œë¶€í„° ë¬´ë£Œ ê±´ê°•ê²€ì§„ì´ ì§„í–‰ë©ë‹ˆë‹¤.
            â—‹ ì¥ì†Œ: â—‹â—‹ë³´ê±´ì†Œ
            â—‹ ì¤€ë¹„ë¬¼: ì‹ ë¶„ì¦ ì§€ì°¸"
        ì‰¬ìš´ ë§ ìš”ì•½:
            "ì–´ë¥´ì‹ , 8ì›” 10ì¼ ì˜¤ì „ 9ì‹œì— â—‹â—‹ë³´ê±´ì†Œì—ì„œ ê±´ê°•ê²€ì§„ì´ ìˆì–´ìš”. ì‹ ë¶„ì¦ ê¼­ ì±™ê¸°ì„¸ìš”."

    ì§ˆë¬¸:
        1. ë‚ ì§œì™€ ì‹œê°„ì´ ëª…í™•í•œê°€ìš”?
        2. ì¥ì†Œì™€ ì¤€ë¹„ë¬¼ì´ ë¹ ì§€ì§€ ì•Šì•˜ë‚˜ìš”?
        3. ì–´ë¥´ì‹ ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë§íˆ¬ë¡œ í‘œí˜„ë˜ì—ˆë‚˜ìš”?

    í•„ìˆ˜ ìš”ì†Œ:
        - ë‚ ì§œì™€ ì‹œê°„
        - ì¥ì†Œ
        - ëŒ€ìƒì ë˜ëŠ” ì‹ ì²­ ì¡°ê±´
        - ì¤€ë¹„ë¬¼ (ì˜ˆ: ì‹ ë¶„ì¦)
        - ì£¼ì˜ì‚¬í•­ (ìˆëŠ” ê²½ìš°)

    ë‹¨ê³„:
        1ë‹¨ê³„: ìœ„ í•­ëª©ì„ í‘œì²˜ëŸ¼ ì •ë¦¬í•˜ê³  ìš”ì•½ í›„ë³´ë¥¼ ì‘ì„±í•˜ì„¸ìš”.  
        2ë‹¨ê³„: ë¹ ì§„ ì •ë³´ ë³´ì™„ í›„ 5ë¬¸ì¥ ìš”ì•½ìœ¼ë¡œ ì••ì¶•í•˜ì„¸ìš”.  
        3ë‹¨ê³„: ë¬¸ì¥ ìˆ˜ë¥¼ ì¤„ì´ë©° ë¶ˆí•„ìš”í•œ í‘œí˜„ì€ ì œê±°í•˜ì„¸ìš”.  
        4ë‹¨ê³„: í•µì‹¬ë§Œ ë‚¨ê²¨ 2~3ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.  
        5ë‹¨ê³„: ë§íˆ¬ë¥¼ ì–´ë¥´ì‹ ê»˜ ì¹œê·¼í•˜ê²Œ ë‹¤ë“¬ìœ¼ì„¸ìš”.

    ì¶œë ¥ ì¡°ê±´:
        - ë°˜ë“œì‹œ 'ì‰¬ìš´ ë§ ìš”ì•½:'ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” 2~3ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        - 1~4 ë‹¨ê³„ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

    """

LIFE_PROMPT = """
    ë‹¤ìŒ ìƒí™œ ì•ˆë‚´ë¬¸ì„ ìš”ì•½í•  ë•Œ, ì•„ë˜ì˜ í•„ìˆ˜ ì •ë³´ê°€ í¬í•¨ë˜ë„ë¡  
    ìŠ¤ìŠ¤ë¡œ ì ê²€í•˜ë©° ë¬¸ì¥ì„ ì •ë¦¬í•˜ê³ , ìµœì¢… ìš”ì•½ì€ 2~3ë¬¸ì¥ìœ¼ë¡œ ì••ì¶•í•˜ì„¸ìš”.

    ë°˜ë“œì‹œ í¬í•¨í•  ì •ë³´:
        - í–‰ì‚¬ëª… ë˜ëŠ” ëª©ì 
        - ë‚ ì§œì™€ ì‹œê°„
        - ì¥ì†Œ
        - ì‹ ì²­ ë°©ë²• ë˜ëŠ” ì—°ë½ì²˜
        - ìœ ì˜ì‚¬í•­ ë˜ëŠ” ì¤€ë¹„ë¬¼

    ìŠ¤ìŠ¤ë¡œ ì ê²€í•˜ì„¸ìš”:
        - ì¼ì •, ì¥ì†Œ, ì‹ ì²­ ë°©ë²•ì´ ëª…í™•í•˜ê²Œ ì „ë‹¬ë˜ì—ˆë‚˜ìš”?
        - ë„ˆë¬´ ë”±ë”±í•˜ê±°ë‚˜ ì–´ìƒ‰í•œ í‘œí˜„ì€ ì—†ë‚˜ìš”?
        - ì–´ë¥´ì‹ ì´ í˜¼ë™ ì—†ì´ ì´í•´í•  ìˆ˜ ìˆì„ê¹Œìš”?

    ë‹¨ê³„:
        1. ìœ„ ì •ë³´ë¥¼ í¬í•¨í•œ ìƒì„¸í•œ ë¬¸ì¥ì„ ë– ì˜¬ë ¤ë³´ì„¸ìš”.
        2. ì¤‘ë³µë˜ê±°ë‚˜ ë¶ˆí•„ìš”í•œ í‘œí˜„ì„ ì •ë¦¬í•˜ê³  ë¬¸ì¥ì„ ì••ì¶•í•˜ì„¸ìš”.
        3. 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ì„ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.

    ì¶œë ¥ ì¡°ê±´:
        - ìµœì¢… ìš”ì•½ 2~3ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        - 1~2 ë‹¨ê³„ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.
    """

FINANCE_PROMPT = """
    ë‹¤ìŒ ê¸ˆìœµ ì•ˆë‚´ë¬¸ì„ ë³´ê³  ì–´ë¥´ì‹ ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ìš”ì•½ì„ 2~3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

    ë‹¨ê³„:
        1. í˜œíƒ, ê¸ˆì•¡, ì¡°ê±´, ì‹ ì²­ë°©ë²•, ê¸°í•œ ë“± ì¤‘ìš”í•œ ì •ë³´ë¥¼ í•­ëª©ë³„ë¡œ ë‚˜ì—´í•˜ì„¸ìš”.
        2. í•­ëª©ë“¤ì„ ê°„ë‹¨í•œ ë¬¸ì¥ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”.
        3. ë¹„ìŠ·í•œ ì •ë³´ëŠ” í•©ì¹˜ê³  ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ì¤„ì´ì„¸ìš”.
        4. ì–´ë¥´ì‹ ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ë§ë¡œ 2~3ë¬¸ì¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬ ìš”ì•½í•˜ì„¸ìš”.

    ì¶œë ¥ ì¡°ê±´:
        - ìµœì¢… ìš”ì•½ë§Œ ì¶œë ¥í•˜ì„¸ìš” (2~3ë¬¸ì¥)
        - ì¤‘ê°„ ë‹¨ê³„ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”
    """
ELSE_PROMPT = """
    ë…¸ì¸ë¶„ë“¤ ëŒ€ìƒìœ¼ë¡œ ì´ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ì„¸ìš”.
    """


PROMPT_MAP = {
    "ê³ ì§€ì„œ": A_PROMPT,
    "ì•ˆë‚´ë¬¸-ê±´ê°•": HEALTH_PROMPT,
    "ì•ˆë‚´ë¬¸-ìƒí™œ": LIFE_PROMPT,
    "ì•ˆë‚´ë¬¸-ê¸ˆìœµ": FINANCE_PROMPT,
    "ê¸°íƒ€": ELSE_PROMPT,
}

MAX_NEW_TOKENS = 256
WARMUP = 1

# ====== ë¶„ë¥˜ í•¨ìˆ˜ ======
def classify_document(image, model, processor):
    messages = [
        {"role": "user", "content": [
            {"type": "image", "image": image},
            {"type": "text", "text": DOC_TYPE_PROMPT}
        ]}
    ]
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    inputs = processor(text=[text], images=[image], return_tensors="pt").to(model.device)
    with torch.no_grad():
        torch.cuda.synchronize()
        t0 = time.perf_counter()
        generated_ids = model.generate(**inputs, max_new_tokens=16)
        torch.cuda.synchronize()
        t1 = time.perf_counter()
    trimmed_ids = [out[len(inp):] for inp, out in zip(inputs.input_ids, generated_ids)]
    result = processor.batch_decode(trimmed_ids, skip_special_tokens=True)[0].strip()
    return result, (t1 - t0)

# ====== ìš”ì•½ í•¨ìˆ˜ ======
def summarize_document(image, prompt_text, model, processor):
    messages = [
        {"role": "user", "content": [
            {"type": "image", "image": image},
            {"type": "text", "text": prompt_text}
        ]}
    ]
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    inputs = processor(text=[text], images=[image], return_tensors="pt").to(model.device)
    with torch.no_grad():
        torch.cuda.synchronize()
        t0 = time.perf_counter()
        generated_ids = model.generate(**inputs, max_new_tokens=MAX_NEW_TOKENS)
        torch.cuda.synchronize()
        t1 = time.perf_counter()
    trimmed_ids = [out[len(inp):] for inp, out in zip(inputs.input_ids, generated_ids)]
    output = processor.batch_decode(trimmed_ids, skip_special_tokens=True)[0].strip()
    return output, (t1 - t0)

# ====== í•œ ë²ˆì˜ íŒ¨ìŠ¤ ì‹¤í–‰ ======
def run_pass(attn_impl: str, label: str):
    get_model.cache_clear()
    gc.collect(); torch.cuda.empty_cache()
    try:
        model = get_model(attn_impl=attn_impl).eval()
    except Exception as e:
        print(f"âŒ [{label}] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    processor = get_processor()
    print(f"\n=== [{label}] ì‹œì‘ (attn_impl={attn_impl}, device={model.device}) ===")

    # ì›Œë°ì—…
    if image_files and WARMUP > 0:
        img0 = Image.open(image_files[0]).convert("RGB")
        _ = classify_document(img0, model, processor)
        _ = summarize_document(img0, ELSE_PROMPT, model, processor)

    # ë³¸ ì‹¤í–‰
    for img_path in image_files:
        image_id = img_path.stem
        try:
            image = Image.open(img_path).convert("RGB")
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨: {e}")
            continue

        doc_type, t_cls = classify_document(image, model, processor)
        prompt_text = PROMPT_MAP.get(doc_type, ELSE_PROMPT)
        output, t_sum = summarize_document(image, prompt_text, model, processor)

        total_time = round(t_cls + t_sum, 4)
        print(f"ğŸ–¼ï¸ {img_path.name} | ìœ í˜•:{doc_type} | ì´ {total_time}s")
        print(f"â†’ ìš”ì•½: {output}\n")

        record = {
            "mode": label,
            "attn_impl": attn_impl,
            "image": img_path.name,
            "doc_type": doc_type,
            "output": output,
            "classify_s": round(t_cls, 4),
            "summary_s": round(t_sum, 4),
            "total_s": total_time
        }
        save_result_jsonl(record)

# ====== í‰ê·  ì‹œê°„ ìš”ì•½ ======
def summarize_overall():
    if not out_path.exists():
        return
    rows = [json.loads(l) for l in out_path.read_text(encoding="utf-8").splitlines()]
    by_mode = {}
    for r in rows:
        by_mode.setdefault(r["mode"], []).append(r)
    print("\n=== ëª¨ë“œë³„ í‰ê·  ì‹œê°„ ===")
    for mode, items in by_mode.items():
        avg_cls = sum(x["classify_s"] for x in items) / len(items)
        avg_sum = sum(x["summary_s"] for x in items) / len(items)
        avg_total = sum(x["total_s"] for x in items) / len(items)
        print(f"{mode:<12} ë¶„ë¥˜ {avg_cls:.3f}s | ìš”ì•½ {avg_sum:.3f}s | ì´ {avg_total:.3f}s (n={len(items)})")

# ====== ì‹¤í–‰ ======
if __name__ == "__main__":
    if not image_files:
        raise SystemExit("ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

    run_pass("sdpa", "Flash OFF")              # Flash OFF
    run_pass("flash_attention_2", "Flash ON")  # Flash ON (ì„¤ì¹˜ í•„ìš”)

    summarize_overall()
    print(f"\nâœ… ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {out_path}")