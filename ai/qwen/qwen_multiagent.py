# qwen_multiagent_debate.py
import sys
from pathlib import Path

# ====== ê²½ë¡œ ì„¤ì • (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€) ======
ROOT_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT_DIR))

from datetime import datetime
from PIL import Image
import torch
import json
import time

# ëª¨ë¸/í”„ë¡œì„¸ì„œ ë¡œë”
from model_loader import get_model, get_processor

# ====== ë””ë ‰í„°ë¦¬/ì…ì¶œë ¥ ê²½ë¡œ ======
base_dir = ROOT_DIR
result_path = base_dir / "qwen" / "results_final.jsonl"
image_dir = base_dir / "data" / "img"
image_files = sorted(list(image_dir.glob("*.jpg")) + list(image_dir.glob("*.png")))

# ====== ëª¨ë¸ ë¡œë“œ ======
model = get_model().eval()     # ì¼ê´€ì„± ìœ„í•´ eval ëª¨ë“œ
processor = get_processor()

# ====== Agent ì—­í•  í”„ë¡¬í”„íŠ¸ ======
EXPLAINER_PROMPT = (
    "ë‹¹ì‹ ì€ í˜¼ì ì‚¬ëŠ” 80ì„¸ í• ë¨¸ë‹ˆì—ê²Œ ë¬¸ì„œë¥¼ ì„¤ëª…í•˜ëŠ” ë”°ëœ»í•œ ì†ì ì—­í• ì…ë‹ˆë‹¤. "
    "ì•„ë˜ ë¬¸ì„œë¥¼ ì½ê³ , ì–´ë¥´ì‹ ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰¬ìš´ ë§ê³¼ ì¹œì ˆí•œ ë§íˆ¬ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”. "
    "ì „ë¬¸ ìš©ì–´ë‚˜ ë”±ë”±í•œ í‘œí˜„ì€ í”¼í•˜ê³ , ë˜ë°•ë˜ë°• ì´ì•¼ê¸°í•˜ë“¯ ë§í•´ ì£¼ì„¸ìš”. "
    "ì–´ë¥´ì‹ ì´ í—·ê°ˆë¦´ ìˆ˜ ìˆëŠ” ë¶€ë¶„ì€ ë¯¸ë¦¬ ì§šì–´ì£¼ê±°ë‚˜ ì˜ˆë¥¼ ë“¤ì–´ ì„¤ëª…í•´ì£¼ì„¸ìš”."
)

GRANDMA_PROMPT = (
    "ë‹¹ì‹ ì€ í˜¼ì ì‚¬ëŠ” 80ì„¸ í• ë¨¸ë‹ˆì…ë‹ˆë‹¤. ëˆ„êµ°ê°€ê°€ ë¬¸ì„œ ë‚´ìš©ì„ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì—ˆì§€ë§Œ, "
    "ì‹œë ¥ë„ ì•½í•˜ê³  í•™êµë„ ì˜¤ë˜ì „ì— ê·¸ë§Œë‘ì–´ ì–´ë ¤ìš´ ë§ì„ ì˜ ì´í•´í•˜ì§€ ëª»í•©ë‹ˆë‹¤. "
    "ì„¤ëª… ì¤‘ì— ì¡°ê¸ˆì´ë¼ë„ ì–´ë ¤ìš´ ë‹¨ì–´, ìµìˆ™í•˜ì§€ ì•Šì€ í‘œí˜„, ë³µì¡í•œ ë‚´ìš©ì´ ë‚˜ì˜¤ë©´ ê¼­ ë¬¼ì–´ë³´ì„¸ìš”. "
    "ì˜ˆ: 'ê·¸ê²Œ ë¬´ìŠ¨ ë§ì´ëƒ', 'ì¡°ê¸ˆ ë” ì‰½ê²Œ ë§í•´ì¤„ë˜?'ì™€ ê°™ì€ ë§íˆ¬ë¡œ 1~2ë¬¸ì¥ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
)

HELPER_PROMPT = (
    "ë‹¹ì‹ ì€ ì†ìì™€ í• ë¨¸ë‹ˆì˜ ëŒ€í™”ë¥¼ ë„ì™€ì£¼ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. "
    "ì†ìê°€ ì„¤ëª…í•œ ë‚´ìš© ì¤‘ ì–´ë¥´ì‹ ì´ ì´í•´í•˜ê¸° ì–´ë ¤ì›Œí•œ ë‹¨ì–´ë‚˜ í‘œí˜„ì´ ìˆë‹¤ë©´ ë” ì‰¬ìš´ ë§ë¡œ ë°”ê¿” ë‹¤ì‹œ ì„¤ëª…í•´ì£¼ì„¸ìš”. "
    "ì¤‘ìš”í•œ ë‚´ìš©ì´ ë¹ ì¡Œë‹¤ë©´ ê°„ë‹¨íˆ ë§ë¶™ì´ê³ , ë„ˆë¬´ ìì„¸í•œ ì •ë³´ëŠ” ì¤„ì—¬ì£¼ì„¸ìš”. "
    "ë§ˆì§€ë§‰ìœ¼ë¡œ, ì†ìì˜ ë§íˆ¬ì™€ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì–´ë¥´ì‹ ì—ê²Œ ì „ë‹¬í•  ìµœì¢… ìš”ì•½ ë¬¸ì¥ì„ 2~3ë¬¸ì¥ìœ¼ë¡œ í•œ ë¬¸ë‹¨ì— ì •ë¦¬í•´ ì£¼ì„¸ìš”."
)

# ====== Qwen í˜¸ì¶œ í•¨ìˆ˜ ======
def query_qwen(pil_image, system_prompt, user_prompt, max_new_tokens=300):
    """
    pil_image: PIL.Image.Image
    system_prompt: str
    user_prompt: str
    """
    # ë©”ì‹œì§€ í¬ë§·: ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ í˜¼í•©
    messages = [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": [
                {"type": "image", "image": pil_image},
                {"type": "text", "text": user_prompt},
            ],
        },
    ]

    # ì±„íŒ… í…œí”Œë¦¿ ì ìš©
    text = processor.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )

    # processorê°€ ì´ë¯¸ì§€ í…ì„œí™”ê¹Œì§€ ì²˜ë¦¬
    inputs = processor(
        text=[text],
        images=[pil_image],
        return_tensors="pt",
        padding=True
    )

    # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
    inputs = {k: v.to(model.device) if hasattr(v, "to") else v for k, v in inputs.items()}

    with torch.no_grad():
        generated_ids = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            do_sample=False,            # ì¬í˜„ì„± ìš°ì„ . í•„ìš”ì‹œ True + temperature/top_p ì¡°ì ˆ
            eos_token_id=processor.tokenizer.eos_token_id,
        )

    # í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ ê¸¸ì´ë§Œí¼ ì˜ë¼ì„œ ë””ì½”ë”©
    input_ids = inputs["input_ids"]
    trimmed = [
        out_ids[len(in_ids):] for in_ids, out_ids in zip(input_ids, generated_ids)
    ]
    output_text = processor.batch_decode(
        trimmed,
        skip_special_tokens=True,
        clean_up_tokenization_spaces=False
    )[0]

    return output_text.strip()

# ====== ê²°ê³¼ ì €ì¥ ======
def save_final_prompt(final_output, elapsed_time):
    result_path.parent.mkdir(parents=True, exist_ok=True)
    record = {
        "output": final_output,
        "infer_time": round(elapsed_time, 2)
    }
    with open(result_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")

# ====== ë©”ì¸ ë£¨í”„ ======
def main():
    if not image_files:
        print(f"âš ï¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        return

    for img_path in image_files:
        try:
            image = Image.open(img_path).convert("RGB")
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨: {img_path} - {e}")
            continue

        start_time = time.time()

        try:
            # 1) ì†ì ì„¤ëª…
            summary = query_qwen(
                image,
                EXPLAINER_PROMPT,
                "ì•„ë˜ ë¬¸ì„œë¥¼ ì–´ë¥´ì‹ ê»˜ ì„¤ëª…í•´ ì£¼ì„¸ìš”. í•µì‹¬ì„ ë¨¼ì € ë§í•˜ê³ , ì˜ˆì‹œë¥¼ 1ê°œë§Œ ë“¤ì–´ì£¼ì„¸ìš”.",
                max_new_tokens=350,
            )

            # 2) í• ë¨¸ë‹ˆ ì§ˆë¬¸ (ì„¤ëª… ìš”ì•½ì— ê¸°ë°˜í•´ ì¶”ê°€ ì§ˆë¬¸ ìœ ë„)
            grandma_reply = query_qwen(
                image,
                GRANDMA_PROMPT,
                f"ì†ìê°€ ì´ë ‡ê²Œ ì„¤ëª…í–ˆì–´ìš”:\n\n{summary}\n\nì´ ì„¤ëª…ì„ ë“£ê³  ê¶ê¸ˆí•œ ì ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ë¬¼ì–´ë´ ì£¼ì„¸ìš”.",
                max_new_tokens=120,
            )

            # 3) ë„ìš°ë¯¸ ìµœì¢… ì •ë¦¬
            helper_final = query_qwen(
                image,
                HELPER_PROMPT,
                f"ì„¤ëª…ì(ì†ì): {summary}\n\ní• ë¨¸ë‹ˆ: {grandma_reply}\n\nìœ„ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì–´ë¥´ì‹  ìš”ì•½ì„ 2~3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.",
                max_new_tokens=200,
            )

            elapsed_time = time.time() - start_time
            print(f"âœ… {img_path.name} ìš”ì•½ ì™„ë£Œ (â± {elapsed_time:.2f}s): {helper_final[:60]}...")
            save_final_prompt(helper_final, elapsed_time)

        except torch.cuda.OutOfMemoryError:
            print("ğŸ’¥ CUDA OOM ë°œìƒ â€” empty_cache() í›„ ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            torch.cuda.empty_cache()
            continue
        except Exception as e:
            print(f"âš ï¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {img_path.name} - {e}")
            continue

if __name__ == "__main__":
    main()
